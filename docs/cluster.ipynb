{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "d61ed362aa666647e884e856f8a6ce510649070e79e0263068f970fc17431b76"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Clustering\n",
    "This notebook is to demonstrate the function of gathering the data from the stock market and creating the clustering algorithm."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Clustering():\n",
    "    '''\n",
    "\n",
    "    Class to gather stock dataset and training the model.\n",
    "\n",
    "    methods:\n",
    "    - gather_data\n",
    "    - cluster_export\n",
    "\n",
    "    '''\n",
    "\n",
    "    def __init__(self, stock_list):\n",
    "        self.stock_list = stock_list\n",
    "    \n",
    "    def __get_increment(self, symbol):\n",
    "        '''\n",
    "\n",
    "        Get the increment of the stock in 1 month period.\n",
    "\n",
    "        return: Float increment.\n",
    "\n",
    "        '''\n",
    "\n",
    "        stock_data = yf.download(\n",
    "            tickers=symbol,\n",
    "            period='1mo',\n",
    "            interval='1wk'\n",
    "        )\n",
    "\n",
    "        stock_data = stock_data['Adj Close']\n",
    "\n",
    "        latest_price = stock_data[-1]\n",
    "        initial_price = stock_data[0]\n",
    "        \n",
    "        if initial_price is None:\n",
    "            initial_price = stock_data[1]\n",
    "        \n",
    "        if latest_price is None:\n",
    "            latest_price = stock_data[-2]\n",
    "\n",
    "        increment = (latest_price - initial_price) / initial_price\n",
    "\n",
    "        return increment\n",
    "\n",
    "    def gather_data(self):\n",
    "        '''\n",
    "\n",
    "        Gathering and formatting stock data into a dataframe and export it to CSV file.\n",
    "\n",
    "        return: None.\n",
    "\n",
    "        '''\n",
    "        list_columns = [\n",
    "            'symbol',\n",
    "            'sector',\n",
    "            'fullTimeEmployees',\n",
    "            'trailingAnnualDividendYield',\n",
    "            'payoutRatio',\n",
    "            'averageDailyVolume10Day',\n",
    "            'trailingAnnualDividendRate',\n",
    "            'averageVolume10days',\n",
    "            'dividendRate',\n",
    "            'beta',\n",
    "            'priceHint',\n",
    "            'trailingPE',\n",
    "            'regularMarketVolume',\n",
    "            'marketCap',\n",
    "            'averageVolume',\n",
    "            'priceToSalesTrailing12Months',\n",
    "            'forwardPE',\n",
    "            'fiveYearAvgDividendYield',\n",
    "            'dividendYield',\n",
    "            'enterpriseToRevenue',\n",
    "            'profitMargins',\n",
    "            'enterpriseToEbitda',\n",
    "            'forwardEps',\n",
    "            'bookValue',\n",
    "            'sharesPercentSharesOut',\n",
    "            'heldPercentInstitutions',\n",
    "            'netIncomeToCommon',\n",
    "            'trailingEps',\n",
    "            'lastDividendValue',\n",
    "            'priceToBook',\n",
    "            'heldPercentInsiders',\n",
    "            'shortRatio',\n",
    "            'enterpriseValue',\n",
    "            'earningsQuarterlyGrowth',\n",
    "            'pegRatio',\n",
    "            'shortPercentOfFloat',\n",
    "            'increment'\n",
    "        ]\n",
    "\n",
    "        df = pd.DataFrame(columns=list_columns)\n",
    "        for symbol in self.stock_list:\n",
    "            try:\n",
    "                print('[INFO] Gathering {} stock data...'.format(symbol))\n",
    "                ticker = yf.Ticker(symbol)\n",
    "\n",
    "                # Create DataFrame from Company Info\n",
    "                company_info = ticker.info\n",
    "                df_info = pd.DataFrame.from_dict(company_info, orient='index').T\n",
    "\n",
    "                if df_info['fullTimeEmployees'] is None:\n",
    "                    pass\n",
    "                else:\n",
    "                    df_info['symbol'] = [symbol]\n",
    "\n",
    "                    # Get increment\n",
    "                    increment = self.__get_increment(symbol)\n",
    "                    df_info['increment'] = [increment]\n",
    "\n",
    "                    # Remove unnecessary column\n",
    "                    df_info.drop(df_info.columns.difference(list_columns), 1, inplace=True)\n",
    "\n",
    "                    # Add to the main dataframe\n",
    "                    df = df.append(df_info, ignore_index=True)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # Export dataset\n",
    "        export = df.to_csv('Stock Dataset.csv', index=False)\n",
    "        print('[SUCCESS] Stock Dataset has been exported to the local directory.')\n",
    "\n",
    "    def normalize_data(self, path):\n",
    "        '''\n",
    "\n",
    "        Normalize the data.\n",
    "\n",
    "        @param path: Folder directory of the normalized dataset.\n",
    "\n",
    "        return: None.\n",
    "\n",
    "        '''\n",
    "\n",
    "        df = pd.read_csv('Stock Dataset.csv')\n",
    "\n",
    "        # Replace inf to nan and remove the row\n",
    "        df = df.fillna(0)\n",
    "        df = df.replace([np.inf, -np.inf], np.nan).dropna(axis=0, inplace=True)\n",
    "\n",
    "        # Index\n",
    "        symbol_list = df['symbol'].values\n",
    "\n",
    "        # Sector\n",
    "        sector_list = df['sector'].values\n",
    "\n",
    "        # Drop non digit columns\n",
    "        df = df.drop(columns=['symbol', 'sector'])\n",
    "\n",
    "        # Normalize\n",
    "        df_values = df.values\n",
    "        scaler = StandardScaler()\n",
    "        df_values_scaled = scaler.fit_transform(df_values)\n",
    "        df = pd.DataFrame(df_values_scaled, columns=list_columns[2:])\n",
    "\n",
    "        # Readd the sector and symbol columns\n",
    "        df['symbol'] = symbol_list\n",
    "        df['sector'] = sector_list\n",
    "\n",
    "        export = df.to_csv('Normalized Stock Dataset.csv', index=False)\n",
    "        print('[SUCCESS] Normalized Stock Dataset has been exported to the local directory.')\n",
    "        \n",
    "    def cluster_export(self, path, index='symbol', n_clusters=500):\n",
    "        '''\n",
    "\n",
    "        Cluster the dataset and export to a new csv dataset with clustered value.\n",
    "\n",
    "        @param path: Folder directory of the normalized dataset.\n",
    "        @param index: Name of the column of index.\n",
    "        @param n_clusters: Number of cluster\n",
    "\n",
    "        return: None.\n",
    "\n",
    "        '''\n",
    "\n",
    "        df = pd.read_csv(path, index_col=index)\n",
    "\n",
    "        model = KMeans(n_clusters=n_clusters)\n",
    "\n",
    "        model = model.fit(df.values)\n",
    "\n",
    "        # Cluster labels\n",
    "        labels = model.labels_\n",
    "\n",
    "        df['cluster'] = labels\n",
    "\n",
    "        df = df['cluster']\n",
    "\n",
    "        export = df.to_csv('Clustered Stock Dataset.csv')\n",
    "        print('[SUCCESS] Clustered Stock Dataset has been exported to the local directory.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "*************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WLTW stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WM stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WMB stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WMC stock data...\n",
      "[INFO] Gathering WMG stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WMK stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WMS stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WMT stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WNC stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WNEB stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WNS stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WNW stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WOMN stock data...\n",
      "[INFO] Gathering WOOD stock data...\n",
      "[INFO] Gathering WOOF stock data...\n",
      "[INFO] Gathering WOR stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WORK stock data...\n",
      "[INFO] Gathering WORX stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WOW stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WPC stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WPF stock data...\n",
      "[INFO] Gathering WPG stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WPM stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WPP stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WPRT stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WPS stock data...\n",
      "[INFO] Gathering WRAP stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WRB stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WRE stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WRI stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WRK stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WRLD stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WRN stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WSBC stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WSBCP stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WSBF stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WSC stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WSFS stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WSM stock data...\n",
      "[INFO] Gathering WSO stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WSR stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WST stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WSTG stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WTBA stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WTER stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WTFC stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WTFCM stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WTFCP stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WTI stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WTM stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WTMF stock data...\n",
      "[INFO] Gathering WTRE stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WTREP stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WTRG stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WTRH stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WTRU stock data...\n",
      "[INFO] Gathering WTS stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WTT stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WTTR stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WU stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WUGI stock data...\n",
      "[INFO] Gathering WVE stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WVFC stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WVVI stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WVVIP stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WW stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WWD stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WWE stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WWJD stock data...\n",
      "[INFO] Gathering WWOW stock data...\n",
      "[INFO] Gathering WWR stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WWW stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WY stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WYNN stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering WYY stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering X stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XAIR stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XAR stock data...\n",
      "[INFO] Gathering XBI stock data...\n",
      "[INFO] Gathering XBIO stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XBIOW stock data...\n",
      "[INFO] Gathering XBIT stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XBUY stock data...\n",
      "[INFO] Gathering XCEM stock data...\n",
      "[INFO] Gathering XCUR stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XDAT stock data...\n",
      "[INFO] Gathering XDIV stock data...\n",
      "[INFO] Gathering XEC stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XEL stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XELA stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XELB stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XENE stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XENT stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XERS stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XES stock data...\n",
      "[INFO] Gathering XFLT stock data...\n",
      "[INFO] Gathering XFOR stock data...\n",
      "[INFO] Gathering XGN stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XHB stock data...\n",
      "[INFO] Gathering XHE stock data...\n",
      "[INFO] Gathering XHR stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XHS stock data...\n",
      "[INFO] Gathering XIN stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XITK stock data...\n",
      "[INFO] Gathering XJH stock data...\n",
      "[INFO] Gathering XJR stock data...\n",
      "[INFO] Gathering XL stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XLB stock data...\n",
      "[INFO] Gathering XLC stock data...\n",
      "[INFO] Gathering XLE stock data...\n",
      "[INFO] Gathering XLF stock data...\n",
      "[INFO] Gathering XLG stock data...\n",
      "[INFO] Gathering XLI stock data...\n",
      "[INFO] Gathering XLK stock data...\n",
      "[INFO] Gathering XLNX stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XLP stock data...\n",
      "[INFO] Gathering XLRE stock data...\n",
      "[INFO] Gathering XLRN stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XLSR stock data...\n",
      "[INFO] Gathering XLU stock data...\n",
      "[INFO] Gathering XLV stock data...\n",
      "[INFO] Gathering XLY stock data...\n",
      "[INFO] Gathering XM stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XME stock data...\n",
      "[INFO] Gathering XMHQ stock data...\n",
      "[INFO] Gathering XMLV stock data...\n",
      "[INFO] Gathering XMMO stock data...\n",
      "[INFO] Gathering XMPT stock data...\n",
      "[INFO] Gathering XMVM stock data...\n",
      "[INFO] Gathering XNCR stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XNET stock data...\n",
      "[INFO] Gathering XNTK stock data...\n",
      "[INFO] Gathering XOG stock data...\n",
      "[INFO] Gathering XOM stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XOMA stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XOMAP stock data...\n",
      "[INFO] Gathering XONE stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XOP stock data...\n",
      "[INFO] Gathering XOUT stock data...\n",
      "[INFO] Gathering XP stock data...\n",
      "[INFO] Gathering XPDIU stock data...\n",
      "[INFO] Gathering XPEL stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XPER stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XPEV stock data...\n",
      "[INFO] Gathering XPH stock data...\n",
      "[INFO] Gathering XPL stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XPO stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XPOA stock data...\n",
      "[INFO] Gathering XPP stock data...\n",
      "[INFO] Gathering XRAY stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XRLV stock data...\n",
      "[INFO] Gathering XRT stock data...\n",
      "[INFO] Gathering XRX stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XSD stock data...\n",
      "[INFO] Gathering XSHD stock data...\n",
      "[INFO] Gathering XSHQ stock data...\n",
      "[INFO] Gathering XSLV stock data...\n",
      "[INFO] Gathering XSMO stock data...\n",
      "[INFO] Gathering XSOE stock data...\n",
      "[INFO] Gathering XSPA stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XSVM stock data...\n",
      "[INFO] Gathering XSW stock data...\n",
      "[INFO] Gathering XT stock data...\n",
      "[INFO] Gathering XTL stock data...\n",
      "[INFO] Gathering XTLB stock data...\n",
      "[INFO] Gathering XTN stock data...\n",
      "[INFO] Gathering XTNT stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XVV stock data...\n",
      "[INFO] Gathering XVZ stock data...\n",
      "[INFO] Gathering XWEB stock data...\n",
      "[INFO] Gathering XXII stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XYF stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XYL stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XYLD stock data...\n",
      "[INFO] Gathering XYLG stock data...\n",
      "[INFO] Gathering Y stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YAC stock data...\n",
      "[INFO] Gathering YALA stock data...\n",
      "[INFO] Gathering YANG stock data...\n",
      "[INFO] Gathering YCBD stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YCL stock data...\n",
      "[INFO] Gathering YCS stock data...\n",
      "[INFO] Gathering YDEC stock data...\n",
      "[INFO] Gathering YELL stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YELP stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YETI stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YEXT stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YGMZ stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YI stock data...\n",
      "[INFO] Gathering YINN stock data...\n",
      "[INFO] Gathering YJ stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YLD stock data...\n",
      "[INFO] Gathering YLDE stock data...\n",
      "[INFO] Gathering YMAB stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YMTX stock data...\n",
      "[INFO] Gathering YNDX stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YOLO stock data...\n",
      "[INFO] Gathering YORW stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YPF stock data...\n",
      "[INFO] Gathering YQ stock data...\n",
      "[INFO] Gathering YRD stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YSAC stock data...\n",
      "[INFO] Gathering YSACU stock data...\n",
      "[INFO] Gathering YSACW stock data...\n",
      "[INFO] Gathering YSG stock data...\n",
      "[INFO] Gathering YTEN stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YTRA stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YUM stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YUMC stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YVR stock data...\n",
      "[INFO] Gathering YXI stock data...\n",
      "[INFO] Gathering YY stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YYY stock data...\n",
      "[INFO] Gathering Z stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZAZZT stock data...\n",
      "[INFO] Gathering ZBH stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZBRA stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZBZX stock data...\n",
      "[INFO] Gathering ZBZZT stock data...\n",
      "[INFO] Gathering ZCAN stock data...\n",
      "[INFO] Gathering ZCMD stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZCZZT stock data...\n",
      "[INFO] Gathering ZDEU stock data...\n",
      "[INFO] Gathering ZDGE stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZEAL stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZEN stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZEPP stock data...\n",
      "[INFO] Gathering ZEUS stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZEXIT stock data...\n",
      "[INFO] Gathering ZG stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZGBR stock data...\n",
      "[INFO] Gathering ZGNX stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZGYH stock data...\n",
      "[INFO] Gathering ZGYHR stock data...\n",
      "[INFO] Gathering ZGYHU stock data...\n",
      "[INFO] Gathering ZGYHW stock data...\n",
      "[INFO] Gathering ZHOK stock data...\n",
      "[INFO] Gathering ZI stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZIEXT stock data...\n",
      "[INFO] Gathering ZIG stock data...\n",
      "[INFO] Gathering ZIM stock data...\n",
      "[INFO] Gathering ZION stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZIONL stock data...\n",
      "[INFO] Gathering ZIONN stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZIONO stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZIONP stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZIOP stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZIXI stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZJPN stock data...\n",
      "[INFO] Gathering ZJZZT stock data...\n",
      "[INFO] Gathering ZKIN stock data...\n",
      "[INFO] Gathering ZLAB stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZM stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZNGA stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZNH stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZNTE stock data...\n",
      "[INFO] Gathering ZNTEU stock data...\n",
      "[INFO] Gathering ZNTEW stock data...\n",
      "[INFO] Gathering ZNTL stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZOM stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZROZ stock data...\n",
      "[INFO] Gathering ZS stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZSAN stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZSL stock data...\n",
      "[INFO] Gathering ZTEST stock data...\n",
      "[INFO] Gathering ZTO stock data...\n",
      "[INFO] Gathering ZTR stock data...\n",
      "[INFO] Gathering ZTS stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZUMZ stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZUO stock data...\n",
      "[INFO] Gathering ZVO stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZVV stock data...\n",
      "[INFO] Gathering ZVZZC stock data...\n",
      "[INFO] Gathering ZVZZT stock data...\n",
      "[INFO] Gathering ZWRKU stock data...\n",
      "[INFO] Gathering ZWZZT stock data...\n",
      "[INFO] Gathering ZXIET stock data...\n",
      "[INFO] Gathering ZXZZT stock data...\n",
      "[INFO] Gathering ZYME stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZYNE stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZYXI stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Input contains infinity or a value too large for dtype('float64').",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1b4c72e06946>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Run to gather the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mclustering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-38387444d067>\u001b[0m in \u001b[0;36mgather_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mdf_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mdf_values_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_values_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist_columns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    761\u001b[0m         \"\"\"\n\u001b[1;32m    762\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m         X = self._validate_data(X, accept_sparse=('csr', 'csc'),\n\u001b[0m\u001b[1;32m    764\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m                                 force_all_finite='allow-nan', reset=first_call)\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'no_validation'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    664\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "with open('tickers.json', 'r') as f:\n",
    "    json_tickers = f.read()\n",
    "    list_tickers = json.loads(json_tickers)\n",
    "\n",
    "test_tickers = ['AAPL', 'MSFT', 'VOO', 'AAAU', 'WNC']\n",
    "\n",
    "clustering = Clustering(list_tickers)\n",
    "\n",
    "# Run to gather the data\n",
    "clustering.gather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3\n   fullTimeEmployees  trailingAnnualDividendYield  payoutRatio  \\\n0           0.590821                    -0.998939     0.316525   \n1           0.817333                    -0.367474     1.035412   \n2          -1.408154                     1.366413    -1.351937   \n\n   averageDailyVolume10Day  trailingAnnualDividendRate  averageVolume10days  \\\n0                 1.368480                   -0.366565             1.368480   \n1                -0.375294                    1.366170            -0.375294   \n2                -0.993186                   -0.999605            -0.993186   \n\n   dividendRate      beta  priceHint  trailingPE  ...  priceToBook  \\\n0     -0.377075 -0.150286        0.0    0.652424  ...     1.306679   \n1      1.368944 -1.142667        0.0    0.760414  ...    -0.184892   \n2     -0.991870  1.292953        0.0   -1.412839  ...    -1.121787   \n\n   heldPercentInsiders  shortRatio  enterpriseValue  earningsQuarterlyGrowth  \\\n0            -0.702338   -0.748188         0.902358                 0.671152   \n1            -0.711865   -0.665214         0.491855                 0.742462   \n2             1.414203    1.413402        -1.394213                -1.413614   \n\n   pegRatio  shortPercentOfFloat  increment  symbol       sector  \n0  0.730286            -0.702977  -0.869760    AAPL   Technology  \n1  0.683672            -0.711228  -0.530852    MSFT   Technology  \n2 -1.413957             1.414206   1.400612     WNC  Industrials  \n\n[3 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Stock Dataset.csv')\n",
    "print(len(df))\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "count                     64\nunique                    11\ntop       Financial Services\nfreq                      12\nName: sector, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['sector'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  symbol  cluster\n0      A        0\n1     AA        0\n2    AAA        3\n3   AAAU        3\n4   AACG       11\n"
     ]
    }
   ],
   "source": [
    "df_clustered = pd.read_csv('Clustered Stock Dataset.csv')\n",
    "\n",
    "print(df_clustered.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "symbol_cluster = df_clustered.loc[df_clustered['symbol'] == 'JPM']['cluster'].values[0]\n",
    "print(symbol_cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     symbol  cluster\n692     BAC        7\n1181      C        7\n1538  CMCSA        7\n1723   CSCO        7\n3574     HD        7\n4094   INTC        7\n4374    JNJ        7\n4394    JPM        7\n4534     KO        7\n4863     MA        7\n5171    MRK        7\n5185     MS        7\n5602    NVS        7\n5774   ORCL        7\n5966    PEP        7\n5981    PFE        7\n6011     PG        7\n7932    UNH        7\n8028      V        7\n8311     VZ        7\n"
     ]
    }
   ],
   "source": [
    "same_cluster = df_clustered.loc[df_clustered['cluster'] == symbol_cluster]\n",
    "print(same_cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}