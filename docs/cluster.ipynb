{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "d61ed362aa666647e884e856f8a6ce510649070e79e0263068f970fc17431b76"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Clustering\n",
    "This notebook is to demonstrate the function of gathering the data from the stock market and creating the clustering algorithm."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Clustering():\n",
    "    '''\n",
    "\n",
    "    Class to gather stock dataset and training the model.\n",
    "\n",
    "    methods:\n",
    "    - gather_data\n",
    "    - cluster_export\n",
    "\n",
    "    '''\n",
    "\n",
    "    def __init__(self, stock_list):\n",
    "        self.stock_list = stock_list\n",
    "    \n",
    "    def __get_increment(self, symbol):\n",
    "        '''\n",
    "\n",
    "        Get the increment of the stock in 1 month period.\n",
    "\n",
    "        return: Float increment.\n",
    "\n",
    "        '''\n",
    "\n",
    "        stock_data = yf.download(\n",
    "            tickers=symbol,\n",
    "            period='1mo',\n",
    "            interval='1wk'\n",
    "        )\n",
    "\n",
    "        stock_data = stock_data['Adj Close']\n",
    "\n",
    "        latest_price = stock_data[-1]\n",
    "        initial_price = stock_data[0]\n",
    "        \n",
    "        if initial_price is None:\n",
    "            initial_price = stock_data[1]\n",
    "        \n",
    "        if latest_price is None:\n",
    "            latest_price = stock_data[-2]\n",
    "\n",
    "        increment = (latest_price - initial_price) / initial_price\n",
    "\n",
    "        return increment\n",
    "\n",
    "    def gather_data(self):\n",
    "        '''\n",
    "\n",
    "        Gathering and formatting stock data into a dataframe and export it to CSV file.\n",
    "\n",
    "        return: None.\n",
    "\n",
    "        '''\n",
    "        list_columns = [\n",
    "            'symbol',\n",
    "            'sector',\n",
    "            'fullTimeEmployees',\n",
    "            'trailingAnnualDividendYield',\n",
    "            'payoutRatio',\n",
    "            'averageDailyVolume10Day',\n",
    "            'trailingAnnualDividendRate',\n",
    "            'averageVolume10days',\n",
    "            'dividendRate',\n",
    "            'beta',\n",
    "            'priceHint',\n",
    "            'trailingPE',\n",
    "            'regularMarketVolume',\n",
    "            'marketCap',\n",
    "            'averageVolume',\n",
    "            'priceToSalesTrailing12Months',\n",
    "            'forwardPE',\n",
    "            'fiveYearAvgDividendYield',\n",
    "            'dividendYield',\n",
    "            'enterpriseToRevenue',\n",
    "            'profitMargins',\n",
    "            'enterpriseToEbitda',\n",
    "            'forwardEps',\n",
    "            'bookValue',\n",
    "            'sharesPercentSharesOut',\n",
    "            'heldPercentInstitutions',\n",
    "            'netIncomeToCommon',\n",
    "            'trailingEps',\n",
    "            'lastDividendValue',\n",
    "            'priceToBook',\n",
    "            'heldPercentInsiders',\n",
    "            'shortRatio',\n",
    "            'enterpriseValue',\n",
    "            'earningsQuarterlyGrowth',\n",
    "            'pegRatio',\n",
    "            'shortPercentOfFloat',\n",
    "            'increment'\n",
    "        ]\n",
    "\n",
    "        df = pd.DataFrame(columns=list_columns)\n",
    "        for symbol in self.stock_list:\n",
    "            try:\n",
    "                print('[INFO] Gathering {} stock data...'.format(symbol))\n",
    "                ticker = yf.Ticker(symbol)\n",
    "\n",
    "                # Create DataFrame from Company Info\n",
    "                company_info = ticker.info\n",
    "                df_info = pd.DataFrame.from_dict(company_info, orient='index').T\n",
    "\n",
    "                df_info['symbol'] = [symbol]\n",
    "\n",
    "                # Get increment\n",
    "                increment = self.__get_increment(symbol)\n",
    "                df_info['increment'] = [increment]\n",
    "\n",
    "                # Remove unnecessary column\n",
    "                df_info.drop(df_info.columns.difference(list_columns), 1, inplace=True)\n",
    "\n",
    "                # Add to the main dataframe\n",
    "                df = df.append(df_info, ignore_index=True)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # Fill NaN value to 0\n",
    "        df = df.fillna(0)\n",
    "\n",
    "        export = df.to_csv('Stock Dataset.csv', index=False)\n",
    "        print('[SUCCESS] Stock Dataset has been exported to the local directory.')\n",
    "\n",
    "    def normalize_dataset(self, path, index='symbol'):\n",
    "        '''\n",
    "\n",
    "        Cluster the dataset and export to a new csv dataset with clustered value.\n",
    "\n",
    "        @param path: Folder directory of the dataset.\n",
    "        @param index: Name of the column of index.\n",
    "\n",
    "        return: None.\n",
    "\n",
    "        '''\n",
    "\n",
    "        df = pd.read_csv(path, index_col=index)\n",
    "\n",
    "        # Remove inf and nan row\n",
    "        df = df.replace([np.inf, -np.inf], np.nan).dropna(axis=0)\n",
    "\n",
    "        # Store columns name and index\n",
    "        columns = df.columns\n",
    "        index_column = df.index\n",
    "\n",
    "        df_values = df.values\n",
    "\n",
    "        # Define scaler\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        df_values_scaled = scaler.fit_transform(df_values)\n",
    "\n",
    "        df = pd.DataFrame(df_values_scaled, columns=columns, index=index_column)\n",
    "\n",
    "        export = df.to_csv('Normalized Stock Dataset.csv')\n",
    "        print('[SUCCESS] Normalized Stock Dataset has been exported to the local directory.')\n",
    "\n",
    "    def cluster_export(self, path, index='symbol', n_clusters=500):\n",
    "        '''\n",
    "\n",
    "        Cluster the dataset and export to a new csv dataset with clustered value.\n",
    "\n",
    "        @param path: Folder directory of the normalized dataset.\n",
    "        @param index: Name of the column of index.\n",
    "        @param n_clusters: Number of cluster\n",
    "\n",
    "        return: None.\n",
    "\n",
    "        '''\n",
    "\n",
    "        df = pd.read_csv(path, index_col=index)\n",
    "\n",
    "        model = KMeans(n_clusters=n_clusters)\n",
    "\n",
    "        model = model.fit(df.values)\n",
    "\n",
    "        # Cluster labels\n",
    "        labels = model.labels_\n",
    "\n",
    "        df['cluster'] = labels\n",
    "\n",
    "        df = df['cluster']\n",
    "\n",
    "        export = df.to_csv('Clustered Stock Dataset.csv')\n",
    "        print('[SUCCESS] Normalized Stock Dataset has been exported to the local directory.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "************]  1 of 1 completed\n",
      "[INFO] Gathering XAR stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XBI stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XBIO stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XBIOW stock data...\n",
      "[INFO] Gathering XBIT stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XBUY stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XCEM stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XCUR stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XDAT stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XDIV stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XEC stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XEL stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XELA stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XELB stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XENE stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XENT stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XERS stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XES stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XFLT stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XFOR stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XGN stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XHB stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XHE stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XHR stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XHS stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XIN stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XITK stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XJH stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XJR stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XL stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XLB stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XLC stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XLE stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XLF stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XLG stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XLI stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XLK stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XLNX stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XLP stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XLRE stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XLRN stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XLSR stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XLU stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XLV stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XLY stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XM stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XME stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XMHQ stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XMLV stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XMMO stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XMPT stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XMVM stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XNCR stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XNET stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XNTK stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XOG stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XOM stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XOMA stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XOMAP stock data...\n",
      "[INFO] Gathering XONE stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XOP stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XOUT stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XP stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XPDIU stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XPEL stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XPER stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XPEV stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XPH stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XPL stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XPO stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XPOA stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XPP stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XRAY stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XRLV stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XRT stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XRX stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XSD stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XSHD stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XSHQ stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XSLV stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XSMO stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XSOE stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XSPA stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XSVM stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XSW stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XT stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XTL stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XTLB stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XTN stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XTNT stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XVV stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XVZ stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XWEB stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XXII stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XYF stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XYL stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XYLD stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering XYLG stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering Y stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YAC stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YALA stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YANG stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YCBD stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YCL stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YCS stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YDEC stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YELL stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YELP stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YETI stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YEXT stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YGMZ stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YI stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YINN stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YJ stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YLD stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YLDE stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YMAB stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YMTX stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YNDX stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YOLO stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YORW stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YPF stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YQ stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YRD stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YSAC stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YSACU stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YSACW stock data...\n",
      "[INFO] Gathering YSG stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YTEN stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YTRA stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YUM stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YUMC stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YVR stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YXI stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YY stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering YYY stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering Z stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZAZZT stock data...\n",
      "[INFO] Gathering ZBH stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZBRA stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZBZX stock data...\n",
      "[INFO] Gathering ZBZZT stock data...\n",
      "[INFO] Gathering ZCAN stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZCMD stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZCZZT stock data...\n",
      "[INFO] Gathering ZDEU stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZDGE stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZEAL stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZEN stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZEPP stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZEUS stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZEXIT stock data...\n",
      "[INFO] Gathering ZG stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZGBR stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZGNX stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZGYH stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZGYHR stock data...\n",
      "[INFO] Gathering ZGYHU stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZGYHW stock data...\n",
      "[INFO] Gathering ZHOK stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZI stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZIEXT stock data...\n",
      "[INFO] Gathering ZIG stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZIM stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZION stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZIONL stock data...\n",
      "[INFO] Gathering ZIONN stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZIONO stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZIONP stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZIOP stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZIXI stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZJPN stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZJZZT stock data...\n",
      "[INFO] Gathering ZKIN stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZLAB stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZM stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZNGA stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZNH stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZNTE stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZNTEU stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZNTEW stock data...\n",
      "[INFO] Gathering ZNTL stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZOM stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZROZ stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZS stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZSAN stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZSL stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZTEST stock data...\n",
      "[INFO] Gathering ZTO stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZTR stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZTS stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZUMZ stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZUO stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZVO stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZVV stock data...\n",
      "[INFO] Gathering ZVZZC stock data...\n",
      "[INFO] Gathering ZVZZT stock data...\n",
      "[INFO] Gathering ZWRKU stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZWZZT stock data...\n",
      "[INFO] Gathering ZXIET stock data...\n",
      "[INFO] Gathering ZXZZT stock data...\n",
      "[INFO] Gathering ZYME stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZYNE stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[INFO] Gathering ZYXI stock data...\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[SUCCESS] Stock Dataset has been exported to the local directory.\n"
     ]
    }
   ],
   "source": [
    "with open('tickers.json', 'r') as f:\n",
    "    json_tickers = f.read()\n",
    "    list_tickers = json.loads(json_tickers)\n",
    "\n",
    "test_tickers = ['AAPL', 'MSFT']\n",
    "\n",
    "clustering = Clustering(list_tickers)\n",
    "\n",
    "# Run to gather the data\n",
    "clustering.gather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            sector  fullTimeEmployees  trailingAnnualDividendYield  \\\nsymbol                                                               \nAAPL    Technology             147000                     0.006668   \nMSFT    Technology             163000                     0.009077   \n\n        payoutRatio  averageDailyVolume10Day  trailingAnnualDividendRate  \\\nsymbol                                                                     \nAAPL         0.2177                123191000                       0.807   \nMSFT         0.3115                 32066483                       2.140   \n\n        averageVolume10days  dividendRate      beta  priceHint  ...  \\\nsymbol                                                          ...   \nAAPL              123191000          0.82  1.251354          2  ...   \nMSFT               32066483          2.24  0.812567          2  ...   \n\n        trailingEps  lastDividendValue  priceToBook  heldPercentInsiders  \\\nsymbol                                                                     \nAAPL          3.687              0.205    31.501522              0.00065   \nMSFT          6.707              0.560    13.605075              0.00059   \n\n        shortRatio  enterpriseValue  earningsQuarterlyGrowth  pegRatio  \\\nsymbol                                                                   \nAAPL          0.97    2067080282112                    0.293      2.02   \nMSFT          1.36    1728870350848                    0.327      1.82   \n\n        shortPercentOfFloat  increment  \nsymbol                                  \nAAPL                 0.0060  -0.045276  \nMSFT                 0.0055  -0.023319  \n\n[2 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Stock Dataset.csv', index_col='symbol')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 36)) while a minimum of 1 is required by StandardScaler.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-182-82b048438eff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclustering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Stock Dataset.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Normalized Stock Dataset.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_normalized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-179-1434c2526c83>\u001b[0m in \u001b[0;36mnormalize_dataset\u001b[0;34m(self, path, index)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdf_values_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_values_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    761\u001b[0m         \"\"\"\n\u001b[1;32m    762\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m         X = self._validate_data(X, accept_sparse=('csr', 'csc'),\n\u001b[0m\u001b[1;32m    764\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m                                 force_all_finite='allow-nan', reset=first_call)\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'no_validation'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m             raise ValueError(\"Found array with %d sample(s) (shape=%s) while a\"\n\u001b[0m\u001b[1;32m    670\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                              % (n_samples, array.shape, ensure_min_samples,\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 36)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "clustering.normalize_dataset('Stock Dataset.csv')\n",
    "\n",
    "df_normalized = pd.read_csv('Normalized Stock Dataset.csv')\n",
    "\n",
    "print(df_normalized.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[SUCCESS] Normalized Stock Dataset has been exported to the local directory.\n"
     ]
    }
   ],
   "source": [
    "clustering.cluster_export('Normalized Stock Dataset.csv', n_clusters=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  symbol  cluster\n0      A        0\n1     AA        0\n2    AAA        3\n3   AAAU        3\n4   AACG       11\n"
     ]
    }
   ],
   "source": [
    "df_clustered = pd.read_csv('Clustered Stock Dataset.csv')\n",
    "\n",
    "print(df_clustered.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "symbol_cluster = df_clustered.loc[df_clustered['symbol'] == 'JPM']['cluster'].values[0]\n",
    "print(symbol_cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     symbol  cluster\n692     BAC        7\n1181      C        7\n1538  CMCSA        7\n1723   CSCO        7\n3574     HD        7\n4094   INTC        7\n4374    JNJ        7\n4394    JPM        7\n4534     KO        7\n4863     MA        7\n5171    MRK        7\n5185     MS        7\n5602    NVS        7\n5774   ORCL        7\n5966    PEP        7\n5981    PFE        7\n6011     PG        7\n7932    UNH        7\n8028      V        7\n8311     VZ        7\n"
     ]
    }
   ],
   "source": [
    "same_cluster = df_clustered.loc[df_clustered['cluster'] == symbol_cluster]\n",
    "print(same_cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}